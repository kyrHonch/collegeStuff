{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AozudenlIsS",
        "outputId": "a0709d0d-d0c5-4acb-fd9b-86b547833ebf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6nD6b0jnhck",
        "outputId": "2372a668-cd93-4c54-98c3-a7b6af339e35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Interactive-AI\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Interactive-AI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDLJh4KIaMxk"
      },
      "source": [
        "## First I tried using Colab but it didn't work because it needs utils.py file, so i used VS code , but I will be pasting the code for each python file I used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LW726aGMXUNe"
      },
      "source": [
        "## I know you taught in class today but I didn't have time to implement it. Sorry for that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7BMLHbZniPB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fu6Zxe9Wa12I"
      },
      "source": [
        "### data_loader.py (Part A)\n",
        "\n",
        "I only worked on the dataset grumpifyBprocessed.\n",
        "\n",
        "I changed the num_workers to 4 from 1. From what I understood that the data loader will use four worker processes to load data in parallel which is better.\n",
        "\n",
        "\n",
        "when opts.data_aug is set to 'deluxe', the data augmentation pipeline involves resizing, random cropping, random horizontal flipping, converting to a tensor, and normalization. These transformations are applied to the input images during the data loading process, contributing to increased variability in the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKlrrljJniRt"
      },
      "outputs": [],
      "source": [
        "\n",
        "import glob\n",
        "import os\n",
        "import PIL.Image as Image\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "\n",
        "class CustomDataSet(Dataset):\n",
        "\n",
        "    def __init__(self, main_dir, ext='*.png', transform=None):\n",
        "        self.main_dir = main_dir\n",
        "        self.transform = transform if transform is not None else transforms.ToTensor()\n",
        "        all_imgs = glob.glob(os.path.join(main_dir, ext))\n",
        "        self.total_imgs = all_imgs\n",
        "        print(os.path.join(main_dir, ext))\n",
        "        print(len(self.total_imgs))\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.total_imgs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_loc = self.total_imgs[idx]\n",
        "        image = Image.open(img_loc).convert(\"RGB\")\n",
        "        tensor_image = self.transform(image)\n",
        "        return tensor_image, 0.\n",
        "\n",
        "def get_data_loader(data_path, opts):\n",
        "    \"\"\"Creates data loaders.\"\"\"\n",
        "    basic_transform = transforms.Compose([\n",
        "        transforms.Resize(opts.image_size, Image.BICUBIC),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    ])\n",
        "    if opts.data_aug == 'basic':\n",
        "        transform = basic_transform\n",
        "    elif opts.data_aug == 'deluxe':\n",
        "        transform = transforms.Compose([\n",
        "            transforms.RandomResizedCrop(opts.image_size),\n",
        "            transforms.RandomRotation(10),  # Adjust the angle as needed\n",
        "            #transforms.RandomHorizontalFlip(),\n",
        "            transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "        ])\n",
        "\n",
        "    dataset = CustomDataSet('cat/grumpifyBprocessed', opts.ext, transform)\n",
        "\n",
        "    dloader = DataLoader(dataset=dataset, batch_size=opts.batch_size, shuffle=True, num_workers=4)\n",
        "\n",
        "    return dloader\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJkarSZya7XY"
      },
      "source": [
        "### models.py (Part B and C only Implementation)\n",
        "\n",
        "I commented out the CycleGenerator class since it was needed.\n",
        "\n",
        "#### DC Generator:\n",
        "\n",
        "The generator is defined by a series of deconvolutional (transpose convolution) layers (deconv). Deconvolutional layers are used to upsample the input noise vector to generate realistic images.\n",
        "\n",
        "\n",
        "The forward method takes a noise vector z as input and passes it through the defined deconvolutional layers with ReLU activation functions.\n",
        "The output of the last layer uses the hyperbolic tangent (F.tanh) activation function, which scales the output to values between -1 and 1, suitable for image data.\n",
        "\n",
        "#### DCDiscriminator\n",
        "\n",
        "The discriminator is defined by a series of convolutional layers (conv). Convolutional layers are used to downsample the input image and extract hierarchical features.\n",
        "\n",
        "The forward method takes an input tensor x and passes it through the defined convolutional layers with ReLU activation functions.\n",
        "The output of the last convolutional layer is passed through a final convolutional layer with no activation function (F.relu) and no normalization (norm=None).\n",
        "The output is squeezed to remove dimensions of size 1, resulting in a 1-dimensional tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1dl1KWrp-oO"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import init\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def deconv(in_channels, out_channels, kernel_size, stride=2, padding=1, norm='batch'):\n",
        "    \"\"\"Creates a transposed-convolutional layer, with optional batch normalization.\n",
        "    \"\"\"\n",
        "    layers = []\n",
        "    layers.append(nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, bias=False))\n",
        "    if norm == 'batch':\n",
        "        layers.append(nn.BatchNorm2d(out_channels))\n",
        "    elif norm == 'instance':\n",
        "        layers.append(nn.InstanceNorm2d(out_channels))\n",
        "\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "def conv(in_channels, out_channels, kernel_size, stride=2, padding=1, norm='batch', init_zero_weights=False):\n",
        "    \"\"\"Creates a convolutional layer, with optional batch normalization.\n",
        "    \"\"\"\n",
        "    layers = []\n",
        "    conv_layer = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=False)\n",
        "    if init_zero_weights:\n",
        "        init.normal_(conv_layer.weight, mean=0.0, std=0.02)\n",
        "    layers.append(conv_layer)\n",
        "\n",
        "    if norm == 'batch':\n",
        "        layers.append(nn.BatchNorm2d(out_channels))\n",
        "    elif norm == 'instance':\n",
        "        layers.append(nn.InstanceNorm2d(out_channels))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class DCGenerator(nn.Module):\n",
        "    def __init__(self, noise_size, conv_dim=64):\n",
        "        super(DCGenerator, self).__init__()\n",
        "\n",
        "        ###########################################\n",
        "        ##   FILL THIS IN: CREATE ARCHITECTURE   ##\n",
        "        ###########################################\n",
        "\n",
        "        self.deconv1 = deconv(noise_size, conv_dim * 4, 4, 1, 0, norm='instance')\n",
        "        self.deconv2 = deconv(conv_dim * 4, conv_dim * 2, 4, 2, 1, norm='instance')\n",
        "        self.deconv3 = deconv(conv_dim * 2, conv_dim, 4, 2, 1, norm='instance')\n",
        "        self.deconv4 = deconv(conv_dim, 3, 4, 2, 1, norm='instance')\n",
        "        self.deconv5 = deconv(3, 3, 4, 2, 1, norm=None)  # No normalization in the last layer\n",
        "\n",
        "    def forward(self, z):\n",
        "        \"\"\"Generates an image given a sample of random noise.\n",
        "\n",
        "            Input\n",
        "            -----\n",
        "                z: BS x noise_size x 1 x 1   -->  16x100x1x1\n",
        "\n",
        "            Output\n",
        "            ------\n",
        "                out: BS x channels x image_width x image_height  -->  16x3x32x32\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        ###########################################\n",
        "        ##   FILL THIS IN: FORWARD PASS   ##\n",
        "        ###########################################\n",
        "        x = F.leaky_relu(self.deconv1(z), negative_slope=0.2)\n",
        "        x = F.leaky_relu(self.deconv2(x), negative_slope=0.2)\n",
        "        x = F.leaky_relu(self.deconv3(x), negative_slope=0.2)\n",
        "        x = F.leaky_relu(self.deconv4(x), negative_slope=0.2)\n",
        "        x = F.tanh(self.deconv5(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "class ResnetBlock(nn.Module):\n",
        "    def __init__(self, conv_dim, norm):\n",
        "        super(ResnetBlock, self).__init__()\n",
        "        self.conv_layer = conv(in_channels=conv_dim, out_channels=conv_dim, kernel_size=3, stride=1, padding=1, norm=norm)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = x + self.conv_layer(x)\n",
        "        return out\n",
        "\n",
        "\n",
        "class DCDiscriminator(nn.Module):\n",
        "    \"\"\"Defines the architecture of the discriminator network.\n",
        "       Note: Both discriminators D_X and D_Y have the same architecture in this assignment.\n",
        "    \"\"\"\n",
        "    def __init__(self, conv_dim=64, norm='batch'):\n",
        "        super(DCDiscriminator, self).__init__()\n",
        "\n",
        "        ###########################################\n",
        "        ##   FILL THIS IN: CREATE ARCHITECTURE   ##\n",
        "        ###########################################\n",
        "\n",
        "        self.conv1 = conv(3, conv_dim, 4, 2, padding=1, norm='instance')\n",
        "        self.conv2 = conv(conv_dim, conv_dim * 2, 4, 2, padding=1, norm='instance')\n",
        "        self.conv3 = conv(conv_dim * 2, conv_dim * 4, 4, 2, padding=1, norm='instance')\n",
        "        self.conv4 = conv(conv_dim * 4, conv_dim * 8, 4, 2, padding=1, norm='instance')\n",
        "        self.conv5 = conv(conv_dim * 8, 1, 4, 1, padding=0, norm=None)  # No padding in the last layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.conv1(x))\n",
        "\n",
        "        ###########################################\n",
        "        ##   FILL THIS IN: FORWARD PASS   ##\n",
        "        ###########################################\n",
        "        out = F.leaky_relu(self.conv1(x), negative_slope=0.2)\n",
        "        out = F.leaky_relu(self.conv2(out), negative_slope=0.2)\n",
        "        out = F.leaky_relu(self.conv3(out), negative_slope=0.2)\n",
        "        out = F.leaky_relu(self.conv4(out), negative_slope=0.2)\n",
        "        out = self.conv5(out).squeeze()\n",
        "        return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvJOMkiKbAG_"
      },
      "source": [
        "### vanilla_gan.py (Part D)\n",
        "\n",
        "Creates generator (G) and discriminator (D) models.\n",
        "Sets up Adam optimizers for both generator and discriminator.\n",
        "\n",
        "Computes discriminator loss on real and fake images.\n",
        "Computes generator loss.\n",
        "Updates discriminator parameters every two iterations.\n",
        "Prints and logs loss information.\n",
        "Saves generated samples and model parameters at specified intervals.\n",
        "\n",
        "\n",
        " the script generates images and saves them to the specified directories during training, providing a visual representation of the training progress.\n",
        "\n",
        "\n",
        " Here, (D(real_images) - 1) represents the difference between the discriminator's output on real images and the target value (1 for real images).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zr5FB5Yrp-sg"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "import imageio\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Numpy & Scipy imports\n",
        "import numpy as np\n",
        "\n",
        "# Torch imports\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision import transforms\n",
        "\n",
        "# Local imports\n",
        "import utils\n",
        "from data_loader import get_data_loader\n",
        "from models import DCGenerator, DCDiscriminator\n",
        "\n",
        "\n",
        "SEED = 11\n",
        "\n",
        "# Set the random seed manually for reproducibility.\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "\n",
        "\n",
        "def print_models(G, D):\n",
        "    \"\"\"Prints model information for the generators and discriminators.\n",
        "    \"\"\"\n",
        "    print(\"                    G                  \")\n",
        "    print(\"---------------------------------------\")\n",
        "    print(G)\n",
        "    print(\"---------------------------------------\")\n",
        "\n",
        "    print(\"                    D                  \")\n",
        "    print(\"---------------------------------------\")\n",
        "    print(D)\n",
        "    print(\"---------------------------------------\")\n",
        "\n",
        "\n",
        "def create_model(opts):\n",
        "    \"\"\"Builds the generators and discriminators.\n",
        "    \"\"\"\n",
        "    G = DCGenerator(noise_size=opts.noise_size, conv_dim=opts.conv_dim)\n",
        "    D = DCDiscriminator(conv_dim=opts.conv_dim)\n",
        "\n",
        "    print_models(G, D)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        G.cuda()\n",
        "        D.cuda()\n",
        "        print('Models moved to GPU.')\n",
        "\n",
        "    return G, D\n",
        "\n",
        "\n",
        "def create_image_grid(array, ncols=None):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    num_images, channels, cell_h, cell_w = array.shape\n",
        "\n",
        "    if not ncols:\n",
        "        ncols = int(np.sqrt(num_images))\n",
        "    nrows = int(np.math.floor(num_images / float(ncols)))\n",
        "    result = np.zeros((cell_h*nrows, cell_w*ncols, channels), dtype=array.dtype)\n",
        "    for i in range(0, nrows):\n",
        "        for j in range(0, ncols):\n",
        "            result[i*cell_h:(i+1)*cell_h, j*cell_w:(j+1)*cell_w, :] = array[i*ncols+j].transpose(1, 2, 0)\n",
        "\n",
        "    if channels == 1:\n",
        "        result = result.squeeze()\n",
        "    return result\n",
        "\n",
        "\n",
        "def checkpoint(iteration, G, D, opts):\n",
        "    \"\"\"Saves the parameters of the generator G and discriminator D.\n",
        "    \"\"\"\n",
        "    G_path = os.path.join(opts.checkpoint_dir, 'G_iter%d.pkl' % iteration)\n",
        "    D_path = os.path.join(opts.checkpoint_dir, 'D_iter%d.pkl' % iteration)\n",
        "    torch.save(G.state_dict(), G_path)\n",
        "    torch.save(D.state_dict(), D_path)\n",
        "\n",
        "\n",
        "def save_samples(G, fixed_noise, iteration, opts):\n",
        "    generated_images = G(fixed_noise)\n",
        "    generated_images = utils.to_data(generated_images)\n",
        "\n",
        "    # Convert the data type to uint8\n",
        "    generated_images = (generated_images * 255).astype(np.uint8)\n",
        "\n",
        "    grid = create_image_grid(generated_images)\n",
        "\n",
        "    # Save the grid as an image\n",
        "    path = os.path.join(opts.sample_dir, 'sample-{:06d}.png'.format(iteration))\n",
        "    imageio.imwrite(path, grid)\n",
        "    print('Saved {}'.format(path))\n",
        "\n",
        "\n",
        "\n",
        "def save_images(images, iteration, opts, name):\n",
        "    grid = create_image_grid(utils.to_data(images))\n",
        "\n",
        "    # Convert pixel values to uint8\n",
        "    grid = (grid * 255).astype(np.uint8)\n",
        "\n",
        "    path = os.path.join(opts.sample_dir, '{:s}-{:06d}.png'.format(name, iteration))\n",
        "    imageio.imwrite(path, grid)\n",
        "    print('Saved {}'.format(path))\n",
        "\n",
        "\n",
        "\n",
        "def sample_noise(dim):\n",
        "    \"\"\"\n",
        "    Generate a PyTorch Variable of uniform random noise.\n",
        "\n",
        "    Input:\n",
        "    - batch_size: Integer giving the batch size of noise to generate.\n",
        "    - dim: Integer giving the dimension of noise to generate.\n",
        "\n",
        "    Output:\n",
        "    - A PyTorch Variable of shape (batch_size, dim, 1, 1) containing uniform\n",
        "      random noise in the range (-1, 1).\n",
        "    \"\"\"\n",
        "    return utils.to_var(torch.rand(batch_size, dim) * 2 - 1).unsqueeze(2).unsqueeze(3)\n",
        "\n",
        "\n",
        "def training_loop(train_dataloader, opts):\n",
        "    \"\"\"Runs the training loop.\n",
        "        * Saves checkpoints every opts.checkpoint_every iterations\n",
        "        * Saves generated samples every opts.sample_every iterations\n",
        "    \"\"\"\n",
        "\n",
        "    # Create generators and discriminators\n",
        "    G, D = create_model(opts)\n",
        "\n",
        "    # Create optimizers for the generators and discriminators\n",
        "    g_optimizer = optim.Adam(G.parameters(), opts.lr, [opts.beta1, opts.beta2])\n",
        "    d_optimizer = optim.Adam(D.parameters(), opts.lr, [opts.beta1, opts.beta2])\n",
        "\n",
        "\n",
        "\n",
        "    # Generate fixed noise for sampling from the generator\n",
        "    fixed_noise = sample_noise(opts.noise_size)  # batch_size x noise_size x 1 x 1\n",
        "\n",
        "    iteration = 1\n",
        "\n",
        "    total_train_iters = opts.num_epochs * len(train_dataloader)\n",
        "\n",
        "    for epoch in range(opts.num_epochs):\n",
        "\n",
        "        for batch in train_dataloader:\n",
        "\n",
        "            real_images, labels = batch\n",
        "            real_images, labels = utils.to_var(real_images), utils.to_var(labels).long().squeeze()\n",
        "\n",
        "            #######################################python vanilla_gan.py --num_epochs=100 --data_aug=deluxe#########\n",
        "            ###         TRAIN THE DISCRIMINATOR         ####\n",
        "            ################################################\n",
        "\n",
        "            d_optimizer.zero_grad()\n",
        "\n",
        "            # FILL THIS IN\n",
        "            # 1. Compute the discriminator loss on real images\n",
        "            D_real_loss = torch.mean((D(real_images) - 1) ** 2)\n",
        "\n",
        "            # 2. Sample noise\n",
        "            noise = sample_noise(opts.noise_size)\n",
        "\n",
        "            # 3. Generate fake images from the noise\n",
        "            fake_images = G(noise)\n",
        "\n",
        "            # 4. Compute the discriminator loss on the fake images\n",
        "            D_fake_loss = torch.mean(D(fake_images) ** 2)\n",
        "\n",
        "            D_total_loss = D_real_loss + D_fake_loss\n",
        "            if iteration % 2 == 0:\n",
        "                D_total_loss.backward()\n",
        "                d_optimizer.step()\n",
        "\n",
        "            ###########################################\n",
        "            ###          TRAIN THE GENERATOR        ###\n",
        "            ###########################################\n",
        "\n",
        "            g_optimizer.zero_grad()\n",
        "\n",
        "            # FILL THIS IN\n",
        "            # 1. Sample noise\n",
        "            noise = sample_noise(opts.noise_size)\n",
        "\n",
        "            # 2. Generate fake images from the noise\n",
        "            fake_images = G(noise)\n",
        "\n",
        "            # 3. Compute the generator loss\n",
        "            G_loss = torch.mean((D(fake_images) - 1) ** 2)\n",
        "\n",
        "            G_loss.backward()\n",
        "            g_optimizer.step()\n",
        "\n",
        "\n",
        "            # Print the log info\n",
        "            if iteration % opts.log_step == 0:\n",
        "                print('Iteration [{:4d}/{:4d}] | D_real_loss: {:6.4f} | D_fake_loss: {:6.4f} | G_loss: {:6.4f}'.format(\n",
        "                       iteration, total_train_iters, D_real_loss.item(), D_fake_loss.item(), G_loss.item()))\n",
        "            # todo: add fake loss, real loss, G loss to tensorboard\n",
        "\n",
        "            # Save the generated samples\n",
        "            if iteration % opts.sample_every == 0:\n",
        "                save_samples(G, fixed_noise, iteration, opts)\n",
        "                save_images(real_images, iteration, opts, 'real')\n",
        "\n",
        "            # Save the model parameters\n",
        "            if iteration % opts.checkpoint_every == 0:\n",
        "                checkpoint(iteration, G, D, opts)\n",
        "\n",
        "            iteration += 1\n",
        "\n",
        "\n",
        "def main(opts):\n",
        "    \"\"\"Loads the data, creates checkpoint and sample directories, and starts the training loop.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create a dataloader for the training images\n",
        "    dataloader = get_data_loader(opts.data, opts)\n",
        "\n",
        "    # Create checkpoint and sample directories\n",
        "    utils.create_dir(opts.checkpoint_dir)\n",
        "    utils.create_dir(opts.sample_dir)\n",
        "\n",
        "    training_loop(dataloader, opts)\n",
        "\n",
        "\n",
        "def create_parser():\n",
        "    \"\"\"Creates a parser for command-line arguments.\n",
        "    \"\"\"\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # Model hyper-parameters\n",
        "    parser.add_argument('--image_size', type=int, default=64, help='The side length N to convert images to NxN.')\n",
        "    parser.add_argument('--conv_dim', type=int, default=32)\n",
        "    parser.add_argument('--noise_size', type=int, default=100)\n",
        "\n",
        "    # Training hyper-parameters\n",
        "    parser.add_argument('--num_epochs', type=int, default=40)\n",
        "    parser.add_argument('--batch_size', type=int, default=16, help='The number of images in a batch.')\n",
        "    parser.add_argument('--num_workers', type=int, default=0, help='The number of threads to use for the DataLoader.')\n",
        "    parser.add_argument('--lr', type=float, default=0.0003, help='The learning rate (default 0.0003)')\n",
        "    parser.add_argument('--beta1', type=float, default=0.5)\n",
        "    parser.add_argument('--beta2', type=float, default=0.999)\n",
        "\n",
        "    # Data sources\n",
        "    parser.add_argument('--data', type=str, default='cat/grumpifyBprocessed', help='Choose the type of emojis to generate.')\n",
        "    parser.add_argument('--data_aug', type=str, default='deluxe', help='data augmentation diff / basic / deluxe')\n",
        "    parser.add_argument('--ext', type=str, default='*.png', help='Choose the type of emojis to generate.')\n",
        "\n",
        "    # Directories and checkpoint/sample iterations\n",
        "    parser.add_argument('--checkpoint_dir', type=str, default='./checkpoints_vanilla')\n",
        "    parser.add_argument('--sample_dir', type=str, default='./vanilla')\n",
        "    parser.add_argument('--log_step', type=int , default=10)\n",
        "    parser.add_argument('--sample_every', type=int , default=200)\n",
        "    parser.add_argument('--checkpoint_every', type=int , default=400)\n",
        "\n",
        "    return parser\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    parser = create_parser()\n",
        "    opts = parser.parse_args()\n",
        "\n",
        "    batch_size = opts.batch_size\n",
        "    opts.sample_dir = os.path.join('output', 'vanilla',\n",
        "                                   '%s_%s' % (os.path.basename(opts.data), opts.data_aug)).replace('/', '\\\\')\n",
        "\n",
        "    if os.path.exists(opts.sample_dir):\n",
        "        cmd = 'del %s/*' % opts.sample_dir\n",
        "        os.system(cmd)\n",
        "    logger = SummaryWriter(opts.sample_dir)\n",
        "    print(opts)\n",
        "    main(opts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgSzrY4HbGC2"
      },
      "source": [
        "## Haven't included the utils.py as I haven't made any changes to it. Also the cycle_gan.py since it wasn't part of the assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33gezAkvgh59"
      },
      "source": [
        "## What I learned from this assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PT7YdaIigyA2"
      },
      "source": [
        "The vanilla_gan defines the architecture of a GAN with a generator (DCGenerator) and a discriminator (DCDiscriminator). These models are convolutional neural networks designed for image generation tasks.\n",
        "\n",
        "The loss functions for both the discriminator and generator are based on the mean squared difference between the discriminator's output and target values (1 for real images and 0 for fake images).\n",
        "\n",
        "The discriminator is trained to minimize the difference between its predictions on real images and the target value (1), and between its predictions on fake images and the target value (0).\n",
        "The generator is trained to minimize the difference between the discriminator's predictions on generated images and the target value (1).\n",
        "\n",
        "\n",
        "this project provided me with a example of how CNNs are used in the architecture of GANs for image generation. It demonstrates the importance of convolutional and deconvolutional layers in learning hierarchical features and generating realistic images. Understanding this architecture was valuable for tasks involving image generation, and other computer vision applications.\n",
        "\n",
        "\n",
        "I used help of ChatGPT for most part , but also I had prior knowledge about CNN so it helped me with the understanding of GANs."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
