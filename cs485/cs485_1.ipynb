{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AozudenlIsS",
        "outputId": "ed25437f-65ec-404b-d503-5daa5e83e2b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xf '/content/cat.tar' -C '/content/'\n"
      ],
      "metadata": {
        "id": "YhM7RR8x_L5O"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "Xg4QnZOSQeKO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_loader(data_path, opts):\n",
        "    \"\"\"Creates data loaders.\n",
        "    \"\"\"\n",
        "    # Basic transformations\n",
        "    basic_transform = transforms.Compose([\n",
        "        transforms.Resize(opts.image_size, Image.BICUBIC),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    ])\n",
        "\n",
        "    # Deluxe transformations\n",
        "    deluxe_transform = transforms.Compose([\n",
        "        transforms.Resize(int(opts.image_size * 1.1)),  # Resize to slightly larger than final size\n",
        "        transforms.RandomCrop(opts.image_size),  # Randomly crop to the final size\n",
        "        transforms.RandomHorizontalFlip(),  # Randomly flip the images horizontally\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    ])\n",
        "\n",
        "    # Choose the transform based on the option\n",
        "    transform = deluxe_transform if opts.data_aug == 'deluxe' else basic_transform\n",
        "\n",
        "    dataset = CustomDataSet(os.path.join('data/', data_path), opts.ext, transform)\n",
        "    dloader = DataLoader(dataset=dataset, batch_size=opts.batch_size, shuffle=True, num_workers=opts.num_workers)\n",
        "\n",
        "    return dloader\n"
      ],
      "metadata": {
        "id": "m7BMLHbZniPB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CMU 16-726 Learning-Based Image Synthesis / Spring 2021, Assignment 3\n",
        "# The code base is based on the great work from CSC 321, U Toronto\n",
        "# https://www.cs.toronto.edu/~rgrosse/courses/csc321_2018/assignments/a4-code.zip\n",
        "\n",
        "import glob\n",
        "import os\n",
        "import PIL.Image as Image\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "class CustomDataSet(Dataset):\n",
        "    \"\"\"Load images under folders\"\"\"\n",
        "    def __init__(self, main_dir, ext='*.png', transform=None):\n",
        "        self.main_dir = main_dir\n",
        "        self.transform = transform\n",
        "        all_imgs = glob.glob(os.path.join(main_dir, ext))\n",
        "        self.total_imgs = all_imgs\n",
        "        print(os.path.join(main_dir, ext))\n",
        "        print(len(self))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.total_imgs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_loc = self.total_imgs[idx]\n",
        "        image = Image.open(img_loc).convert(\"RGB\")\n",
        "        tensor_image = self.transform(image)\n",
        "        return tensor_image, 0.\n",
        "\n",
        "def get_data_loader(data_path, opts):\n",
        "    \"\"\"Creates data loaders.\n",
        "    \"\"\"\n",
        "    basic_transform = transforms.Compose([\n",
        "        transforms.Resize(opts.image_size, Image.BICUBIC),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    ])\n",
        "\n",
        "    if opts.data_aug == 'basic':\n",
        "        transform = basic_transform\n",
        "    elif opts.data_aug == 'deluxe':\n",
        "        load_size = int(1.1 * opts.image_size)\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize((load_size, load_size), Image.BICUBIC),\n",
        "            transforms.RandomCrop(opts.image_size),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "        ])\n",
        "\n",
        "    dataset = CustomDataSet(os.path.join('data/', data_path), opts.ext, transform)\n",
        "    dloader = DataLoader(dataset=dataset, batch_size=opts.batch_size, shuffle=True, num_workers=opts.num_workers)\n",
        "\n",
        "    return dloader"
      ],
      "metadata": {
        "id": "MKlrrljJniRt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### models.py (Part B and C only Implementation)\n",
        "\n",
        "I commented out the CycleGenerator class since it was needed.\n",
        "\n",
        "#### DC Generator:\n",
        "\n",
        "The generator is defined by a series of deconvolutional (transpose convolution) layers (deconv). Deconvolutional layers are used to upsample the input noise vector to generate realistic images.\n",
        "\n",
        "\n",
        "The forward method takes a noise vector z as input and passes it through the defined deconvolutional layers with ReLU activation functions.\n",
        "The output of the last layer uses the hyperbolic tangent (F.tanh) activation function, which scales the output to values between -1 and 1, suitable for image data.\n",
        "\n",
        "#### DCDiscriminator\n",
        "\n",
        "The discriminator is defined by a series of convolutional layers (conv). Convolutional layers are used to downsample the input image and extract hierarchical features.\n",
        "\n",
        "The forward method takes an input tensor x and passes it through the defined convolutional layers with ReLU activation functions.\n",
        "The output of the last convolutional layer is passed through a final convolutional layer with no activation function (F.relu) and no normalization (norm=None).\n",
        "The output is squeezed to remove dimensions of size 1, resulting in a 1-dimensional tensor."
      ],
      "metadata": {
        "id": "CJkarSZya7XY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import init\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def deconv(in_channels, out_channels, kernel_size, stride=2, padding=1, norm='batch'):\n",
        "    \"\"\"Creates a transposed-convolutional layer, with optional batch normalization.\n",
        "    \"\"\"\n",
        "    layers = []\n",
        "    layers.append(nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, bias=False))\n",
        "    if norm == 'batch':\n",
        "        layers.append(nn.BatchNorm2d(out_channels))\n",
        "    elif norm == 'instance':\n",
        "        layers.append(nn.InstanceNorm2d(out_channels))\n",
        "\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "def conv(in_channels, out_channels, kernel_size, stride=2, padding=1, norm='batch', init_zero_weights=False):\n",
        "    \"\"\"Creates a convolutional layer, with optional batch normalization.\n",
        "    \"\"\"\n",
        "    layers = []\n",
        "    conv_layer = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=False)\n",
        "    if init_zero_weights:\n",
        "        init.normal_(conv_layer.weight, mean=0.0, std=0.02)\n",
        "    layers.append(conv_layer)\n",
        "\n",
        "    if norm == 'batch':\n",
        "        layers.append(nn.BatchNorm2d(out_channels))\n",
        "    elif norm == 'instance':\n",
        "        layers.append(nn.InstanceNorm2d(out_channels))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class DCGenerator(nn.Module):\n",
        "    def __init__(self, noise_size, conv_dim=64):\n",
        "        super(DCGenerator, self).__init__()\n",
        "\n",
        "        ###########################################\n",
        "        ##   FILL THIS IN: CREATE ARCHITECTURE   ##\n",
        "        ###########################################\n",
        "\n",
        "        self.deconv1 = deconv(noise_size, conv_dim * 4, 4, 1, 0, norm='instance')\n",
        "        self.deconv2 = deconv(conv_dim * 4, conv_dim * 2, 4, 2, 1, norm='instance')\n",
        "        self.deconv3 = deconv(conv_dim * 2, conv_dim, 4, 2, 1, norm='instance')\n",
        "        self.deconv4 = deconv(conv_dim, 3, 4, 2, 1, norm='instance')\n",
        "        self.deconv5 = deconv(3, 3, 4, 2, 1, norm=None)  # No normalization in the last layer\n",
        "\n",
        "    def forward(self, z):\n",
        "        \"\"\"Generates an image given a sample of random noise.\n",
        "\n",
        "            Input\n",
        "            -----\n",
        "                z: BS x noise_size x 1 x 1   -->  16x100x1x1\n",
        "\n",
        "            Output\n",
        "            ------\n",
        "                out: BS x channels x image_width x image_height  -->  16x3x32x32\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        ###########################################\n",
        "        ##   FILL THIS IN: FORWARD PASS   ##\n",
        "        ###########################################\n",
        "        x = F.leaky_relu(self.deconv1(z), negative_slope=0.2)\n",
        "        x = F.leaky_relu(self.deconv2(x), negative_slope=0.2)\n",
        "        x = F.leaky_relu(self.deconv3(x), negative_slope=0.2)\n",
        "        x = F.leaky_relu(self.deconv4(x), negative_slope=0.2)\n",
        "        x = F.tanh(self.deconv5(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "class ResnetBlock(nn.Module):\n",
        "    def __init__(self, conv_dim, norm):\n",
        "        super(ResnetBlock, self).__init__()\n",
        "        self.conv_layer = conv(in_channels=conv_dim, out_channels=conv_dim, kernel_size=3, stride=1, padding=1, norm=norm)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = x + self.conv_layer(x)\n",
        "        return out\n",
        "\n",
        "\n",
        "class DCDiscriminator(nn.Module):\n",
        "    \"\"\"Defines the architecture of the discriminator network.\n",
        "       Note: Both discriminators D_X and D_Y have the same architecture in this assignment.\n",
        "    \"\"\"\n",
        "    def __init__(self, conv_dim=64, norm='batch'):\n",
        "        super(DCDiscriminator, self).__init__()\n",
        "\n",
        "        ###########################################\n",
        "        ##   FILL THIS IN: CREATE ARCHITECTURE   ##\n",
        "        ###########################################\n",
        "\n",
        "        self.conv1 = conv(3, conv_dim, 4, 2, padding=1, norm='instance')\n",
        "        self.conv2 = conv(conv_dim, conv_dim * 2, 4, 2, padding=1, norm='instance')\n",
        "        self.conv3 = conv(conv_dim * 2, conv_dim * 4, 4, 2, padding=1, norm='instance')\n",
        "        self.conv4 = conv(conv_dim * 4, conv_dim * 8, 4, 2, padding=1, norm='instance')\n",
        "        self.conv5 = conv(conv_dim * 8, 1, 4, 1, padding=0, norm=None)  # No padding in the last layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.conv1(x))\n",
        "\n",
        "        ###########################################\n",
        "        ##   FILL THIS IN: FORWARD PASS   ##\n",
        "        ###########################################\n",
        "        out = F.leaky_relu(self.conv1(x), negative_slope=0.2)\n",
        "        out = F.leaky_relu(self.conv2(out), negative_slope=0.2)\n",
        "        out = F.leaky_relu(self.conv3(out), negative_slope=0.2)\n",
        "        out = F.leaky_relu(self.conv4(out), negative_slope=0.2)\n",
        "        out = self.conv5(out).squeeze()\n",
        "        return out\n",
        "\n"
      ],
      "metadata": {
        "id": "q1dl1KWrp-oO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### vanilla_gan.py (Part D)\n",
        "\n",
        "Creates generator (G) and discriminator (D) models.\n",
        "Sets up Adam optimizers for both generator and discriminator.\n",
        "\n",
        "Computes discriminator loss on real and fake images.\n",
        "Computes generator loss.\n",
        "Updates discriminator parameters every two iterations.\n",
        "Prints and logs loss information.\n",
        "Saves generated samples and model parameters at specified intervals.\n",
        "\n",
        "\n",
        " the script generates images and saves them to the specified directories during training, providing a visual representation of the training progress.\n",
        "\n",
        "\n",
        " Here, (D(real_images) - 1) represents the difference between the discriminator's output on real images and the target value (1 for real images).\n"
      ],
      "metadata": {
        "id": "RvJOMkiKbAG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from models import DCGenerator, DCDiscriminator\n"
      ],
      "metadata": {
        "id": "IiduOntNeFp_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import warnings\n",
        "import imageio\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision import transforms\n",
        "import utils\n",
        "from data_loader import get_data_loader\n",
        "from models import DCGenerator, DCDiscriminator\n",
        "\n",
        "# Ignore warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Seed for reproducibility\n",
        "SEED = 11\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "\n",
        "# Manually set the options usually passed as command-line arguments\n",
        "class Options:\n",
        "    image_size = 64\n",
        "    conv_dim = 64\n",
        "    noise_size = 100\n",
        "    num_epochs = 100\n",
        "    batch_size = 64\n",
        "    num_workers = 2\n",
        "    lr = 0.0002\n",
        "    beta1 = 0.5\n",
        "    beta2 = 0.999\n",
        "    data = '/content/cat/grumpifyBprocessed'  # Update this path\n",
        "    data_aug = 'deluxe'\n",
        "    ext = '*.png'\n",
        "    checkpoint_dir = '/content/checkpoints_vanilla'  # Update this path\n",
        "    sample_dir = '/content/vanilla_samples'  # Update this path\n",
        "    log_step = 10\n",
        "    sample_every = 200\n",
        "    checkpoint_every = 400\n",
        "\n",
        "opts = Options()\n",
        "\n",
        "# Then you can use an instance of this class as your arguments.\n",
        "args = Args()\n",
        "\n",
        "def print_models(G, D):\n",
        "    \"\"\"Prints model information for the generators and discriminators.\n",
        "    \"\"\"\n",
        "    print(\"                    G                  \")\n",
        "    print(\"---------------------------------------\")\n",
        "    print(G)\n",
        "    print(\"---------------------------------------\")\n",
        "\n",
        "    print(\"                    D                  \")\n",
        "    print(\"---------------------------------------\")\n",
        "    print(D)\n",
        "    print(\"---------------------------------------\")\n",
        "\n",
        "\n",
        "def create_model(opts):\n",
        "    \"\"\"Builds the generators and discriminators.\n",
        "    \"\"\"\n",
        "    G = DCGenerator(noise_size=opts.noise_size, conv_dim=opts.conv_dim)\n",
        "    D = DCDiscriminator(conv_dim=opts.conv_dim)\n",
        "\n",
        "    print_models(G, D)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        G.cuda()\n",
        "        D.cuda()\n",
        "        print('Models moved to GPU.')\n",
        "\n",
        "    return G, D\n",
        "\n",
        "\n",
        "def create_image_grid(array, ncols=None):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    num_images, channels, cell_h, cell_w = array.shape\n",
        "\n",
        "    if not ncols:\n",
        "        ncols = int(np.sqrt(num_images))\n",
        "    nrows = int(np.math.floor(num_images / float(ncols)))\n",
        "    result = np.zeros((cell_h*nrows, cell_w*ncols, channels), dtype=array.dtype)\n",
        "    for i in range(0, nrows):\n",
        "        for j in range(0, ncols):\n",
        "            result[i*cell_h:(i+1)*cell_h, j*cell_w:(j+1)*cell_w, :] = array[i*ncols+j].transpose(1, 2, 0)\n",
        "\n",
        "    if channels == 1:\n",
        "        result = result.squeeze()\n",
        "    return result\n",
        "\n",
        "\n",
        "def checkpoint(iteration, G, D, opts):\n",
        "    \"\"\"Saves the parameters of the generator G and discriminator D.\n",
        "    \"\"\"\n",
        "    G_path = os.path.join(opts.checkpoint_dir, 'G_iter%d.pkl' % iteration)\n",
        "    D_path = os.path.join(opts.checkpoint_dir, 'D_iter%d.pkl' % iteration)\n",
        "    torch.save(G.state_dict(), G_path)\n",
        "    torch.save(D.state_dict(), D_path)\n",
        "\n",
        "\n",
        "def save_samples(G, fixed_noise, iteration, opts):\n",
        "    generated_images = G(fixed_noise)\n",
        "    generated_images = utils.to_data(generated_images)\n",
        "\n",
        "    # Convert the data type to uint8\n",
        "    generated_images = (generated_images * 255).astype(np.uint8)\n",
        "\n",
        "    grid = create_image_grid(generated_images)\n",
        "\n",
        "    # Save the grid as an image\n",
        "    path = os.path.join(opts.sample_dir, 'sample-{:06d}.png'.format(iteration))\n",
        "    imageio.imwrite(path, grid)\n",
        "    print('Saved {}'.format(path))\n",
        "\n",
        "\n",
        "\n",
        "def save_images(images, iteration, opts, name):\n",
        "    grid = create_image_grid(utils.to_data(images))\n",
        "\n",
        "    # Convert pixel values to uint8\n",
        "    grid = (grid * 255).astype(np.uint8)\n",
        "\n",
        "    path = os.path.join(opts.sample_dir, '{:s}-{:06d}.png'.format(name, iteration))\n",
        "    imageio.imwrite(path, grid)\n",
        "    print('Saved {}'.format(path))\n",
        "\n",
        "\n",
        "\n",
        "def sample_noise(dim):\n",
        "    \"\"\"\n",
        "    Generate a PyTorch Variable of uniform random noise.\n",
        "\n",
        "    Input:\n",
        "    - batch_size: Integer giving the batch size of noise to generate.\n",
        "    - dim: Integer giving the dimension of noise to generate.\n",
        "\n",
        "    Output:\n",
        "    - A PyTorch Variable of shape (batch_size, dim, 1, 1) containing uniform\n",
        "      random noise in the range (-1, 1).\n",
        "    \"\"\"\n",
        "    return utils.to_var(torch.rand(batch_size, dim) * 2 - 1).unsqueeze(2).unsqueeze(3)\n",
        "\n",
        "\n",
        "def training_loop(train_dataloader, opts):\n",
        "    \"\"\"Runs the training loop.\n",
        "        * Saves checkpoints every opts.checkpoint_every iterations\n",
        "        * Saves generated samples every opts.sample_every iterations\n",
        "    \"\"\"\n",
        "\n",
        "    # Create generators and discriminators\n",
        "    G, D = create_model(opts)\n",
        "\n",
        "    # Create optimizers for the generators and discriminators\n",
        "    g_optimizer = optim.Adam(G.parameters(), opts.lr, [opts.beta1, opts.beta2])\n",
        "    d_optimizer = optim.Adam(D.parameters(), opts.lr, [opts.beta1, opts.beta2])\n",
        "\n",
        "\n",
        "\n",
        "    # Generate fixed noise for sampling from the generator\n",
        "    fixed_noise = sample_noise(opts.noise_size)  # batch_size x noise_size x 1 x 1\n",
        "\n",
        "    iteration = 1\n",
        "\n",
        "    total_train_iters = opts.num_epochs * len(train_dataloader)\n",
        "\n",
        "    for epoch in range(opts.num_epochs):\n",
        "\n",
        "        for batch in train_dataloader:\n",
        "\n",
        "            real_images, labels = batch\n",
        "            real_images, labels = utils.to_var(real_images), utils.to_var(labels).long().squeeze()\n",
        "\n",
        "            #######################################python vanilla_gan.py --num_epochs=100 --data_aug=deluxe#########\n",
        "            ###         TRAIN THE DISCRIMINATOR         ####\n",
        "            ################################################\n",
        "\n",
        "            d_optimizer.zero_grad()\n",
        "\n",
        "            # FILL THIS IN\n",
        "            # 1. Compute the discriminator loss on real images\n",
        "            D_real_loss = torch.mean((D(real_images) - 1) ** 2)\n",
        "\n",
        "            # 2. Sample noise\n",
        "            noise = sample_noise(opts.noise_size)\n",
        "\n",
        "            # 3. Generate fake images from the noise\n",
        "            fake_images = G(noise)\n",
        "\n",
        "            # 4. Compute the discriminator loss on the fake images\n",
        "            D_fake_loss = torch.mean(D(fake_images) ** 2)\n",
        "\n",
        "            D_total_loss = D_real_loss + D_fake_loss\n",
        "            if iteration % 2 == 0:\n",
        "                D_total_loss.backward()\n",
        "                d_optimizer.step()\n",
        "\n",
        "            ###########################################\n",
        "            ###          TRAIN THE GENERATOR        ###\n",
        "            ###########################################\n",
        "\n",
        "            g_optimizer.zero_grad()\n",
        "\n",
        "            # FILL THIS IN\n",
        "            # 1. Sample noise\n",
        "            noise = sample_noise(opts.noise_size)\n",
        "\n",
        "            # 2. Generate fake images from the noise\n",
        "            fake_images = G(noise)\n",
        "\n",
        "            # 3. Compute the generator loss\n",
        "            G_loss = torch.mean((D(fake_images) - 1) ** 2)\n",
        "\n",
        "            G_loss.backward()\n",
        "            g_optimizer.step()\n",
        "\n",
        "\n",
        "            # Print the log info\n",
        "            if iteration % opts.log_step == 0:\n",
        "                print('Iteration [{:4d}/{:4d}] | D_real_loss: {:6.4f} | D_fake_loss: {:6.4f} | G_loss: {:6.4f}'.format(\n",
        "                       iteration, total_train_iters, D_real_loss.item(), D_fake_loss.item(), G_loss.item()))\n",
        "            # todo: add fake loss, real loss, G loss to tensorboard\n",
        "\n",
        "            # Save the generated samples\n",
        "            if iteration % opts.sample_every == 0:\n",
        "                save_samples(G, fixed_noise, iteration, opts)\n",
        "                save_images(real_images, iteration, opts, 'real')\n",
        "\n",
        "            # Save the model parameters\n",
        "            if iteration % opts.checkpoint_every == 0:\n",
        "                checkpoint(iteration, G, D, opts)\n",
        "\n",
        "            iteration += 1\n",
        "\n",
        "\n",
        "def main(opts):\n",
        "    \"\"\"Loads the data, creates checkpoint and sample directories, and starts the training loop.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create a dataloader for the training images\n",
        "    dataloader = get_data_loader(opts.data, opts)\n",
        "\n",
        "    # Create checkpoint and sample directories\n",
        "    utils.create_dir(opts.checkpoint_dir)\n",
        "    utils.create_dir(opts.sample_dir)\n",
        "\n",
        "    training_loop(dataloader, opts)\n",
        "\n",
        "\n",
        "def create_parser():\n",
        "    \"\"\"Creates a parser for command-line arguments.\n",
        "    \"\"\"\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # Model hyper-parameters\n",
        "    parser.add_argument('--image_size', type=int, default=64, help='The side length N to convert images to NxN.')\n",
        "    parser.add_argument('--conv_dim', type=int, default=32)\n",
        "    parser.add_argument('--noise_size', type=int, default=100)\n",
        "\n",
        "    # Training hyper-parameters\n",
        "    parser.add_argument('--num_epochs', type=int, default=40)\n",
        "    parser.add_argument('--batch_size', type=int, default=16, help='The number of images in a batch.')\n",
        "    parser.add_argument('--num_workers', type=int, default=0, help='The number of threads to use for the DataLoader.')\n",
        "    parser.add_argument('--lr', type=float, default=0.0003, help='The learning rate (default 0.0003)')\n",
        "    parser.add_argument('--beta1', type=float, default=0.5)\n",
        "    parser.add_argument('--beta2', type=float, default=0.999)\n",
        "\n",
        "    # Data sources\n",
        "    parser.add_argument('--data', type=str, default='cat/grumpifyBprocessed', help='Choose the type of emojis to generate.')\n",
        "    parser.add_argument('--data_aug', type=str, default='deluxe', help='data augmentation diff / basic / deluxe')\n",
        "    parser.add_argument('--ext', type=str, default='*.png', help='Choose the type of emojis to generate.')\n",
        "\n",
        "    # Directories and checkpoint/sample iterations\n",
        "    parser.add_argument('--checkpoint_dir', type=str, default='./checkpoints_vanilla')\n",
        "    parser.add_argument('--sample_dir', type=str, default='./vanilla')\n",
        "    parser.add_argument('--log_step', type=int , default=10)\n",
        "    parser.add_argument('--sample_every', type=int , default=200)\n",
        "    parser.add_argument('--checkpoint_every', type=int , default=400)\n",
        "\n",
        "    return parser\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    parser = create_parser()\n",
        "    opts = parser.parse_args()\n",
        "\n",
        "    batch_size = opts.batch_size\n",
        "    opts.sample_dir = os.path.join('output', 'vanilla',\n",
        "                                   '%s_%s' % (os.path.basename(opts.data), opts.data_aug)).replace('/', '\\\\')\n",
        "\n",
        "    if os.path.exists(opts.sample_dir):\n",
        "        cmd = 'del %s/*' % opts.sample_dir\n",
        "        os.system(cmd)\n",
        "    logger = SummaryWriter(opts.sample_dir)\n",
        "    print(opts)\n",
        "    main(opts)"
      ],
      "metadata": {
        "id": "Zr5FB5Yrp-sg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "751ac769-d024-444e-dc0d-a20e286ac1fa"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: colab_kernel_launcher.py [-h] [--image_size IMAGE_SIZE] [--conv_dim CONV_DIM]\n",
            "                                [--noise_size NOISE_SIZE] [--num_epochs NUM_EPOCHS]\n",
            "                                [--batch_size BATCH_SIZE] [--num_workers NUM_WORKERS] [--lr LR]\n",
            "                                [--beta1 BETA1] [--beta2 BETA2] [--data DATA]\n",
            "                                [--data_aug DATA_AUG] [--ext EXT]\n",
            "                                [--checkpoint_dir CHECKPOINT_DIR] [--sample_dir SAMPLE_DIR]\n",
            "                                [--log_step LOG_STEP] [--sample_every SAMPLE_EVERY]\n",
            "                                [--checkpoint_every CHECKPOINT_EVERY]\n",
            "colab_kernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-34eb6f7f-0e53-487b-a57f-15504416d522.json\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(\"Current directory:\", os.getcwd())\n",
        "print(\"Contents:\", os.listdir('.'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIgj-AVwehh3",
        "outputId": "17feb337-7ac3-466c-d69e-a43573366ec6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current directory: /content\n",
            "Contents: ['.config', 'drive', '__pycache__', 'cat.tar', 'models.py', 'cat', 'data_loader.py', 'pokemon.tar', 'utils.py', 'cycle_gan.py', 'vanilla_gan.py', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What I learned from this assignment"
      ],
      "metadata": {
        "id": "33gezAkvgh59"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The vanilla_gan defines the architecture of a GAN with a generator (DCGenerator) and a discriminator (DCDiscriminator). These models are convolutional neural networks designed for image generation tasks.\n",
        "\n",
        "The loss functions for both the discriminator and generator are based on the mean squared difference between the discriminator's output and target values (1 for real images and 0 for fake images).\n",
        "\n",
        "The discriminator is trained to minimize the difference between its predictions on real images and the target value (1), and between its predictions on fake images and the target value (0).\n",
        "The generator is trained to minimize the difference between the discriminator's predictions on generated images and the target value (1).\n",
        "\n",
        "\n",
        "this project provided me with a example of how CNNs are used in the architecture of GANs for image generation. It demonstrates the importance of convolutional and deconvolutional layers in learning hierarchical features and generating realistic images. Understanding this architecture was valuable for tasks involving image generation, and other computer vision applications.\n",
        "\n",
        "\n",
        "I used help of ChatGPT for most part , but also I had prior knowledge about CNN so it helped me with the understanding of GANs."
      ],
      "metadata": {
        "id": "PT7YdaIigyA2"
      }
    }
  ]
}